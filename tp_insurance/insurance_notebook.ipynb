{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(\"insurance.csv\")\n",
    "dataset_insurance = pd.DataFrame(csv)\n",
    "dataset_insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns\n",
    "\n",
    "- age: age of primary beneficiary\n",
    "\n",
    "- sex: insurance contractor gender, female, male\n",
    "\n",
    "- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "\n",
    "- children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "- smoker: Smoking\n",
    "\n",
    "- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "- charges: Individual medical costs billed by health insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_insurance.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que sex, smoker et region sont des objets, on va donc les transformer en données numériques <br>\n",
    "\n",
    "- Sex: male=0, female=1\n",
    "- Smoker: no=0, yes=1\n",
    "- Region: northeast=0, southeast=1, southwest=2, northwest=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de valeur colonne sex ['female' 'male']\n",
      "nombre de valeur colonne smoker ['yes' 'no']\n",
      "nombre de valeur colonne region ['southwest' 'southeast' 'northwest' 'northeast']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges\n",
       "0   19    1  27.900         0       1       0  16884.92400\n",
       "1   18    0  33.770         1       0       1   1725.55230\n",
       "2   28    0  33.000         3       0       1   4449.46200\n",
       "3   33    0  22.705         0       0       1  21984.47061\n",
       "4   32    0  28.880         0       0       1   3866.85520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"nombre de valeur colonne sex\",dataset_insurance['sex'].unique())\n",
    "print(\"nombre de valeur colonne smoker\",dataset_insurance['smoker'].unique())\n",
    "print(\"nombre de valeur colonne region\",dataset_insurance['region'].unique())\n",
    "\n",
    "dataset_insurance.isnull()\n",
    "\n",
    "dataset_insurance['sex']=dataset_insurance['sex'].replace('male',0)\n",
    "dataset_insurance['sex']=dataset_insurance['sex'].replace('female',1)\n",
    "\n",
    "dataset_insurance['smoker']=dataset_insurance['smoker'].replace('no',0)\n",
    "dataset_insurance['smoker']=dataset_insurance['smoker'].replace('yes',1)\n",
    "\n",
    "dataset_insurance['region']=dataset_insurance['region'].replace('northeast',0)\n",
    "dataset_insurance['region']=dataset_insurance['region'].replace('southeast',1)\n",
    "dataset_insurance['region']=dataset_insurance['region'].replace('southwest',0)\n",
    "dataset_insurance['region']=dataset_insurance['region'].replace('northwest',1)\n",
    "\n",
    "dataset_insurance.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparer les datasets ( training et test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_insurance.drop(['charges'],axis=1),dataset_insurance['charges'], test_size=0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients de regression: [ 2.54776907e+02  2.17798094e+01  3.22737384e+02  4.27477330e+02\n",
      "  2.36002895e+04 -1.91285985e+02]\n"
     ]
    }
   ],
   "source": [
    "# créer le modèle de régression multiple \n",
    "# entrainement du modèle de régression \n",
    "reg  = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic = reg.predict(X_test)\n",
    "\n",
    "print(\"coefficients de regression:\",reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 32149530.206277784\n"
     ]
    }
   ],
   "source": [
    "rmse_testData = mean_squared_error(y_test,y_predic)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_testData) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'on a une erreur de prédiction sur les données de test qui est assez élevé. <br>\n",
    "On peut regarder l'erreur sur les données d'entrainement afin de voir si le modèle n'a pas fait de l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : 0.7979668332906551\n",
      "ecart type des residus (erreur de prédiction) 6149.780912361591\n",
      "difference d'erreur entre les deux jeu de données 32143380.425365422\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "y_predic_trainData = reg.predict(X_train)\n",
    "rmse_trainData =math.sqrt(mean_squared_error(y_train,y_predic_trainData))\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test, y_predic, multioutput='uniform_average', force_finite=True))\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_trainData) \n",
    "print(\"difference d'erreur entre les deux jeu de données\",abs(rmse_trainData - rmse_testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il y a une différence d'erreur qui n'est pas si important compte tenu de la valeur élevé des rmse. <br>\n",
    "Ainsi on peut dire qu'il n'y a pas de surapprentissage.\n",
    "On pourrait entrainer d'autre modèle afin de voir s'il n'y pas d'autre modèle encore moins en surapprenttisage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est du score, ce dernier n'est pas mauvais pour un premier entrainement mais il faudrait le tout de même l'améliorer pour une mise en production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut appliquer une méthode de scalling (normalisation entre de valeur), afin de réduire la différence d'interval entre chaque colonne. <br>\n",
    "Pour cela on reduit nos valeurs à un interval [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\rayan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479150</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458434</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex       bmi  children  smoker  region   charges\n",
       "0  0.021739  1.0  0.321227       0.0     1.0     0.0  0.251611\n",
       "1  0.000000  0.0  0.479150       0.2     0.0     1.0  0.009636\n",
       "2  0.217391  0.0  0.458434       0.6     0.0     1.0  0.053115\n",
       "3  0.326087  0.0  0.181464       0.0     0.0     1.0  0.333010\n",
       "4  0.304348  0.0  0.347592       0.0     0.0     1.0  0.043816"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_insurance_normalized=(dataset_insurance-np.min(dataset_insurance))/(np.max(dataset_insurance)-np.min(dataset_insurance))\n",
    "dataset_insurance_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression multiple après Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients de regression: [ 1.87071161e-01  3.47650632e-04  1.91483247e-01  3.41170947e-02\n",
      "  3.76709245e-01 -3.05331843e-03]\n"
     ]
    }
   ],
   "source": [
    "# séparer les datasets ( training et test)\n",
    "X_train_normalized, X_test_normalized, y_train_normalized, y_test_normalized = train_test_split(dataset_insurance_normalized.drop(['charges'],axis=1),dataset_insurance_normalized['charges'], test_size=0.2, random_state= 0)\n",
    "\n",
    "reg.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg.predict(X_test_normalized)\n",
    "\n",
    "print(\"coefficients de regression:\",reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008191294242534976\n",
      "score : 0.7979668332906552\n"
     ]
    }
   ],
   "source": [
    "rmse_testData = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_testData) \n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le score n'a pas énormement changé, ce qui veut dire que notre dataset n'était pas concerné par les problèmes que le scalling permet de résoudre. Autrement dit nos données devait être sensiblement à la même échelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification des paramètres de la régréssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous allons modifier les différents paramètres de la Regression de sklearn afin de voir les repercutions que cela a sur les performances de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008555721530239249\n",
      "coefficients de regression: [ 0.16818737 -0.01035973  0.12959621  0.01804181  0.36953964 -0.0104642 ]\n",
      "score : 0.7889784613935902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# créer le modèle de régression multiple \n",
    "# entrainement du modèle de régression \n",
    "reg  = LinearRegression(fit_intercept=False)\n",
    "reg.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg.predict(X_test_normalized)\n",
    "rmse_fitIntercept_false = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_fitIntercept_false) \n",
    "print(\"coefficients de regression:\",reg.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008191294242534976\n",
      "coefficients de regression: [ 1.87071161e-01  3.47650632e-04  1.91483247e-01  3.41170947e-02\n",
      "  3.76709245e-01 -3.05331843e-03]\n",
      "score : 0.7979668332906552\n"
     ]
    }
   ],
   "source": [
    "# créer le modèle de régression multiple \n",
    "# entrainement du modèle de régression \n",
    "reg  = LinearRegression(n_jobs=20)\n",
    "reg.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg.predict(X_test_normalized)\n",
    "rmse_n_jobs = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_n_jobs) \n",
    "print(\"coefficients de regression:\",reg.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008195446368939263\n",
      "coefficients de regression: [1.87199929e-01 3.74402785e-04 1.90270494e-01 3.43830273e-02\n",
      " 3.76529435e-01 0.00000000e+00]\n",
      "score : 0.7978644236809894\n"
     ]
    }
   ],
   "source": [
    "# créer le modèle de régression multiple \n",
    "# entrainement du modèle de régression \n",
    "reg  = LinearRegression(positive=True)\n",
    "reg.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi en faisant varier les paramètres on remarque que les coefficients du modèle changent. <br>\n",
    "Cependant le score d'évaluation ne change pratiquement pas. <br>\n",
    "On peut en déduire que la variation des paramètres de la fonction LinearRegression n'a pas un impacte significatif sur la performance de nore modèle en sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methode Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on regarde les corrélations pour chaque colone du dataset avec la sortie\n",
    "#@parameter: la matrice de feature, le vecteur de sortie\n",
    "#@return: le premier tableau est le score de corrélation avec la sortie, le deuxième est les P-values associés\n",
    "feature_selection_by_regression =sklearn.feature_selection.f_regression(dataset_insurance_normalized.drop(['charges'],axis=1),dataset_insurance_normalized['charges'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20cde936c80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = dataset_insurance_normalized.drop('charges',axis=1).columns.values\n",
    "\n",
    "X_axis = np.arange(len(X))\n",
    "print(X_axis)\n",
    "plt.bar(X_axis , feature_selection_by_regression[0], 0.4)\n",
    "  \n",
    "plt.xticks(X_axis, X)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Score of correlation with the output\")\n",
    "plt.title(\"Correlation between Features and output\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il y a une forte corrélation entre le facteur \"smoker\" et la sortie \"charges\". <br>\n",
    "Les deux autres sorties qui ont une corrélation intéressante avec la sortie sont le facteur \"age\" et \"bmi\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methode Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4,)</td>\n",
       "      <td>[0.6197648148218988]</td>\n",
       "      <td>0.619765</td>\n",
       "      <td>(smoker,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 4)</td>\n",
       "      <td>[0.7214008260577199]</td>\n",
       "      <td>0.721401</td>\n",
       "      <td>(age, smoker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 2, 4)</td>\n",
       "      <td>[0.7474771588119513]</td>\n",
       "      <td>0.747477</td>\n",
       "      <td>(age, bmi, smoker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 2, 3, 4)</td>\n",
       "      <td>[0.749694530346479]</td>\n",
       "      <td>0.749695</td>\n",
       "      <td>(age, bmi, children, smoker)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 2, 3, 4, 5)</td>\n",
       "      <td>[0.7497680322910479]</td>\n",
       "      <td>0.749768</td>\n",
       "      <td>(age, bmi, children, smoker, region)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5)</td>\n",
       "      <td>[0.7497962726676124]</td>\n",
       "      <td>0.749796</td>\n",
       "      <td>(age, sex, bmi, children, smoker, region)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature_idx             cv_scores avg_score  \\\n",
       "1                (4,)  [0.6197648148218988]  0.619765   \n",
       "2              (0, 4)  [0.7214008260577199]  0.721401   \n",
       "3           (0, 2, 4)  [0.7474771588119513]  0.747477   \n",
       "4        (0, 2, 3, 4)   [0.749694530346479]  0.749695   \n",
       "5     (0, 2, 3, 4, 5)  [0.7497680322910479]  0.749768   \n",
       "6  (0, 1, 2, 3, 4, 5)  [0.7497962726676124]  0.749796   \n",
       "\n",
       "                               feature_names  \n",
       "1                                  (smoker,)  \n",
       "2                              (age, smoker)  \n",
       "3                         (age, bmi, smoker)  \n",
       "4               (age, bmi, children, smoker)  \n",
       "5       (age, bmi, children, smoker, region)  \n",
       "6  (age, sex, bmi, children, smoker, region)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On definit une sequence de selection de type forward (on part d'un vecteur nul)\n",
    "#@parametre: methode d'apprentissage, nombre de facteur souhaiter à la fin, \n",
    "#cette méthode va selectionner executer une selection de type wrapper sur les feature\n",
    "#tout en appliquant à chaque itération un algo de régression linéaire avec pour performance évaluée la mse des feature selectionnées\n",
    "sffs = SFS(LinearRegression(),\n",
    "           k_features=len(dataset_insurance_normalized.drop('charges',axis=1).columns.values),\n",
    "           forward=True,\n",
    "           floating=True,\n",
    "           scoring = 'r2', #mse normalisé \n",
    "           cv = 0)\n",
    "#entrainement du modèle et filtre sur notre dataset \n",
    "feature_names=dataset_insurance_normalized.drop('charges',axis=1).columns.values\n",
    "sffs.fit(dataset_insurance_normalized.drop(['charges'],axis=1),dataset_insurance_normalized['charges'])\n",
    "\n",
    "#Creation d'un dataframe pour les résultats \n",
    "df_SFFS_results = pd.DataFrame(sffs.subsets_).transpose()\n",
    "df_SFFS_results\n",
    "#la sortie nous montre pour chaque itération les features selectionnées ainsi que la performance du modele de ml entrainer (ici regression\n",
    "# linéaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les features ajoutés, s'ajoutent dans le même ordre que leur corrélation avec la sortie (cf methode filter au dessus). <br>\n",
    "Cependant on remarque que l'ajout du paramètre children augmente encore l'avg_score de manière intéressante ainsi on pourrait également ajouter ce facteur au modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methode Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bmi', 'smoker'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sel = SelectFromModel(RandomForestRegressor())\n",
    "sel.fit(dataset_insurance_normalized.drop(['charges'],axis=1), dataset_insurance_normalized['charges'])\n",
    "selected_feat= dataset_insurance_normalized.drop(['charges'],axis=1).columns[(sel.get_support())]\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les paramètres selectionnées sont bmi et smoker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conclure, on peut choisir de selectionner les facteurs 'smoker', 'age', 'bmi' pour un premier modèle. <br> \n",
    "Il pourra être interressant d'ajouter le paramètre 'children' pour l'entrainement d'un second modèle et de comparer ce dernier avec le premier afin de selectionner le plus performant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement avec les features selectionnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008329824105641861\n",
      "coefficients de regression: [0.18873334 0.19095081 0.37710742]\n",
      "score : 0.7945500805653087\n"
     ]
    }
   ],
   "source": [
    "X_train_normalized_fs = X_train_normalized.drop(['sex','children','region'],axis=1)\n",
    "X_test_normalized_fs = X_test_normalized.drop(['sex','children','region'],axis=1)\n",
    "reg  = LinearRegression()\n",
    "reg.fit(X_train_normalized_fs, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg.predict(X_test_normalized_fs)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que notre modèle a un score similaire aux modèles précedents. <br>\n",
    "Ainsi on peut en déduire qu'il n'est pas nécéssaire de garder les facteurs 'sex', 'children' et 'region' pour l'entrainement. <br>\n",
    "Cela permet sur des jeux de données avec beaucoup de facteurs, de réduire le nombre de ces derniers utilisés afin de gagner en temps de calcul ainsi que de réduire la complexité du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Linéaire Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode ridge applique une valeur alpha de type float à la régréssion afin de réduire ses paramètres. <br>\n",
    "Cela permet de ne pas avoir un modèle avec des coefficients trop grands et un écart trop important entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488028</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.108696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557170</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517622</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.442158</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sex       bmi  children  smoker  region\n",
       "621   0.413043  0.0  0.488028       0.8     1.0     0.0\n",
       "194   0.000000  0.0  0.496906       0.0     0.0     1.0\n",
       "240   0.108696  1.0  0.557170       0.4     1.0     0.0\n",
       "1168  0.304348  0.0  0.517622       0.4     0.0     0.0\n",
       "1192  0.869565  1.0  0.442158       0.2     0.0     0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008306895013062403\n",
      "coefficients de regression: [ 1.80405475e-01 -2.35009435e-04  1.68048544e-01  3.31703011e-02\n",
      "  3.67308842e-01 -1.77467686e-03]\n",
      "score : 0.7951156123416604\n"
     ]
    }
   ],
   "source": [
    "reg_ridge = Ridge(alpha=4.2)\n",
    "reg_ridge.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg_ridge.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg_ridge.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que nos coefficients n'ont pas les mêmes valeurs, cependant le score du modèle lors du test a pratiquement la même valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.04057475105430419\n",
      "coefficients de regression: [ 0. -0.  0.  0.  0.  0.]\n",
      "score : -0.0007509437736328284\n"
     ]
    }
   ],
   "source": [
    "reg_lasso = Lasso(alpha=4.2)\n",
    "reg_lasso.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg_lasso.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg_lasso.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les coefficients ont des valeurs nulles. <br>\n",
    "On remarque également que nous avons un score bien plus faible dans le cas de la regession de Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.00835481115633762\n",
      "coefficients de regression: [ 0.17889236 -0.          0.1559625   0.01863117  0.37000772 -0.        ]\n",
      "score : 0.7939337905347813\n"
     ]
    }
   ],
   "source": [
    "reg_lasso = Lasso(alpha=0.001)\n",
    "reg_lasso.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg_lasso.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg_lasso.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque lorsque le coefficient alpha est très faible, les coefficient du modèle ne sont plus égaux à 0, ainsi on peut donc en déduire que la méthode Lasso réduit encore plus les coefficients que la regression de Ridge. <br>\n",
    "Ici nous avions des coefficients assez faible de base c'est donc pourquoi la méthode de Lasso à fait que nos coefficients étaient égale à 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.04057475105430419\n",
      "coefficients de regression: [ 0. -0.  0.  0.  0.  0.]\n",
      "score : -0.0007509437736328284\n"
     ]
    }
   ],
   "source": [
    "reg_elasticNet = ElasticNet(alpha=4.2)\n",
    "reg_elasticNet.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg_elasticNet.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg_elasticNet.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les coefficients ont des valeurs nulles. <br>\n",
    "On remarque également que nous avons un score bien plus faible dans le cas de la regession de Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecart type des residus (erreur de prédiction) 0.008276138395852027\n",
      "coefficients de regression: [ 1.82176151e-01 -0.00000000e+00  1.70213742e-01  2.64105022e-02\n",
      "  3.72067956e-01 -1.76500733e-04]\n",
      "score : 0.7958742051339951\n"
     ]
    }
   ],
   "source": [
    "reg_elasticNet = ElasticNet(alpha=0.001)\n",
    "reg_elasticNet.fit(X_train_normalized, y_train_normalized)\n",
    "# maintenant on passe à la prédiction, donc on applique notre modèle sur le dataset x_test \n",
    "y_predic_normalized = reg_elasticNet.predict(X_test_normalized)\n",
    "rmse_positive = mean_squared_error(y_test_normalized,y_predic_normalized)\n",
    "print(\"ecart type des residus (erreur de prédiction)\",rmse_positive) \n",
    "print(\"coefficients de regression:\",reg_elasticNet.coef_)\n",
    "print(\"score :\",sklearn.metrics.r2_score(y_test_normalized, y_predic_normalized, multioutput='uniform_average', force_finite=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on remarque que comme pour la regression de Lasso, la regression ElasticNet réduit plus facilement les coefficients que Ridge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi on peut conclure que la regression de Ridge s'appliquera lorsque l'on veut réduire des coefficients qui sont de petite/moyenne taille. <br>\n",
    "Tandis que les regressions de Lasso et ElasticNet seront utilisées afin de réduire des coefficients de grandes tailles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334657c8e52fd71d95571d4aa266536ecfae8b05cb25ba6557c72dcb65d7c56a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
